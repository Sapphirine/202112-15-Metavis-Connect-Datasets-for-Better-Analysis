{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[archive]metadata_columns.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"ovy2oXbAgV_Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637188415743,"user_tz":300,"elapsed":168,"user":{"displayName":"Tim Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0Mbx_gve9TlcvS-Od6nAnJwp6jEIt8BeHBKSp=s64","userId":"18355578200475546173"}},"outputId":"93475e61-a4d5-43ae-9b2a-3496d88fe61c"},"source":["from google.colab import drive\n","drive.mount('/content/drive') # , force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"IUeK8fHdgDiQ"},"source":["import pandas as pd \n","import numpy as np\n","import re\n","import os\n","import ast\n","from glob import glob\n","from tqdm import tqdm\n","\n","import ast\n","tqdm.pandas()\n","pd.set_option('display.max_columns', 100)\n","pd.set_option('display.max_rows', 100)\n","pd.set_option('display.max_colwidth', 200)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TYggoeSmLeo3"},"source":["def flatten_list(l):\n","  return [item for sublist in l for item in sublist]\n","\n","from collections import Counter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PMm8Mvq1g7_O"},"source":["metadata_df = pd.read_csv('/content/drive/MyDrive/metavis/socrata_nycopendata_metadata_fetched_20211105.csv')\n","metadata_df['columns'] = metadata_df['columns'].apply(ast.literal_eval)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1FgZXHvohcjd"},"source":["# metadata_df['excel_attachments'] = metadata_df['data_uuid'].progress_apply(lambda data_uuid: sorted(glob('/content/drive/MyDrive/metavis/data_attachments/'+data_uuid+'/*.xlsx')))\n","\n","# def get_excel_header_and_first_row(excel_attachment_path, sheet_number):\n","#   try:\n","#     excel_df = pd.read_excel(excel_attachment_path, sheet_name=sheet_number, nrows=0)\n","#     header = excel_df.columns.tolist()\n","#     excel_df = pd.read_excel(excel_attachment_path, sheet_name=sheet_number, nrows=0, header = 1)\n","#     first_row = excel_df.columns.tolist()\n","#     return header, first_row\n","#   except:\n","#     return [], []\n","\n","# for sheet_number in [1,2]:\n","#   print(sheet_number)\n","#   metadata_df['header_and_first_row_of_excel_files_sheet'+str(sheet_number)] = metadata_df['excel_attachments'].progress_apply(lambda li: [get_excel_header_and_first_row(p, sheet_number = sheet_number) for p in li])\n","#   metadata_df['excel_header_signature_sheet'+str(sheet_number)] = metadata_df['header_and_first_row_of_excel_files_sheet'+str(sheet_number)].progress_apply(lambda files: [ '||'.join(['|'.join([str(field) for field in row[:3]]) for row in file]) for file in files] ) \n","#   metadata_df['attachment_is_data_dictionary_sheet'+str(sheet_number)] = metadata_df['excel_header_signature_sheet'+str(sheet_number)].apply(lambda li: ['Data Dictionary - Column Information' in sig or 'Column Name|Column Description' in sig or 'Column Name|Description' in sig for sig in li])\n","\n","# metadata_df['data_dictionary_file_indices_in_excel_attachments'] = metadata_df[['excel_attachments','attachment_is_data_dictionary_sheet1','attachment_is_data_dictionary_sheet2']].apply(lambda row: list(np.where(np.int0(np.array(row['attachment_is_data_dictionary_sheet1'])|np.array(row['attachment_is_data_dictionary_sheet2']))==1)[0]) if len(row['excel_attachments'])>0 else [], axis=1)\n","# # metadata_df[(metadata_df.excel_attachments.apply(len)>0) & (metadata_df.data_dictionary_file_indices_in_excel_attachments.apply(len)==0)]\n","# metadata_df['data_dictionary_file_path'] = metadata_df[['excel_attachments','data_dictionary_file_indices_in_excel_attachments']].apply(lambda row: row['excel_attachments'][row['data_dictionary_file_indices_in_excel_attachments'][0]] if len(row['data_dictionary_file_indices_in_excel_attachments'])>0 else np.nan,axis=1)\n","# # metadata_df[(metadata_df['columns'].apply(len)==0) & (metadata_df['data_dictionary_file_path'].notnull())]\n","# metadata_df['sheet1_is_data_dictionary'] = metadata_df[['attachment_is_data_dictionary_sheet1','data_dictionary_file_indices_in_excel_attachments']].apply(lambda row: row['attachment_is_data_dictionary_sheet1'][row['data_dictionary_file_indices_in_excel_attachments'][0]] if len(row['data_dictionary_file_indices_in_excel_attachments'])>0 else np.nan,axis=1)\n","# metadata_df['sheet2_is_data_dictionary'] = metadata_df[['attachment_is_data_dictionary_sheet2','data_dictionary_file_indices_in_excel_attachments']].apply(lambda row: row['attachment_is_data_dictionary_sheet2'][row['data_dictionary_file_indices_in_excel_attachments'][0]] if len(row['data_dictionary_file_indices_in_excel_attachments'])>0 else np.nan,axis=1)\n","\n","# def get_data_dictionary(path, sheet_num, data_uuid):\n","#   data_dictionary = pd.read_excel(path, sheet_name = sheet_num)\n","#   if any([col.startswith('Unnamed:') for col in data_dictionary.columns]):\n","#     data_dictionary = pd.read_excel(path, sheet_name = sheet_num, header = 1)\n","#   data_dictionary['data_uuid'] = data_uuid\n","#   return data_dictionary\n","\n","# metadata_df['data_dictionary'] = metadata_df[['data_dictionary_file_path','sheet1_is_data_dictionary','sheet2_is_data_dictionary','data_uuid']].progress_apply(lambda row: get_data_dictionary(row['data_dictionary_file_path'], (1 if row['sheet1_is_data_dictionary'] else 2), row['data_uuid']) if isinstance(row['data_dictionary_file_path'],str) else np.nan,axis=1)\n","\n","# metadata_df[['data_uuid','excel_attachments',\n","#        'header_and_first_row_of_excel_files_sheet1',\n","#        'excel_header_signature_sheet1', 'attachment_is_data_dictionary_sheet1',\n","#        'header_and_first_row_of_excel_files_sheet2',\n","#        'excel_header_signature_sheet2', 'attachment_is_data_dictionary_sheet2',\n","#        'data_dictionary_file_indices_in_excel_attachments',\n","#        'data_dictionary_file_path', 'sheet1_is_data_dictionary',\n","#        'sheet2_is_data_dictionary', 'data_dictionary']].to_csv('/content/drive/MyDrive/metavis/temp.csv',index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3sDIfOB2Dmqv"},"source":["# data_dictionary_paths = sorted(glob('/content/drive/MyDrive/metavis/data_dictionaries/*'))\n","\n","# data_dictionary_list = []\n","\n","# for p in tqdm(data_dictionary_paths):\n","#   tdf = pd.read_csv(p)\n","#   tdf.columns = [re.sub(r'\\(.*?\\)','',col).strip() for col in tdf.columns]\n","#   col_name_correction_mapping = {}\n","#   for col in tdf.columns:\n","#     if 'notes' in col.lower():\n","#       col_name_correction_mapping[col] = 'notes'\n","#       continue\n","#     if 'table' in col.lower() or 'unnamed' in col.lower():\n","#       col_name_correction_mapping[col] = 'REMOVE'\n","#       continue\n","#     if 'term' in col.lower() or 'expected' in col.lower():\n","#       col_name_correction_mapping[col] = 'term'\n","#       continue\n","#     if 'description' in col.lower():\n","#       col_name_correction_mapping[col] = 'description'\n","#       continue\n","#     if 'name' in col.lower():\n","#       col_name_correction_mapping[col] = 'name'\n","#       continue\n","#     if 'type' in col.lower():\n","#       col_name_correction_mapping[col] = 'data_type'\n","#       continue\n","#     if 'data_uuid' == col:\n","#       col_name_correction_mapping[col] = 'data_uuid'\n","#       continue\n","#     col_name_correction_mapping[col] = 'REMOVE'\n","\n","#   tdf = tdf.rename(columns=col_name_correction_mapping)\n","  \n","#   if 'REMOVE' in tdf.columns:\n","#     tdf = tdf.drop(['REMOVE'],axis=1)\n","  \n","#   tdf = (tdf.dropna(how='all',axis=1)).T.drop_duplicates().T\n","\n","#   if len(tdf.columns) != len(set(tdf.columns)):\n","#     tdf = tdf.T.reset_index().drop_duplicates(subset=['index'],keep='first').set_index('index').T\n","#     print('Duplicated column names occur')\n","\n","#   data_dictionary_list.append(tdf)\n","\n","# data_dictionary_df = pd.DataFrame()\n","# for tdf in tqdm(data_dictionary_list):\n","#   data_dictionary_df = data_dictionary_df.append(tdf, ignore_index = True)\n","\n","# data_dictionary_df = data_dictionary_df[['data_uuid','name','description','data_type','term','notes']]\n","# data_dictionary_df.to_csv(X'/content/drive/MyDrive/metavis/combined_data_dictionary.csv',index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h2X4K_5WCsFX"},"source":["### Transform the column information within metadata file"]},{"cell_type":"code","metadata":{"id":"Wld7JARI99W9"},"source":["metadata_df = metadata_df[['data_uuid','columns']].copy()\n","col_metadata_df = metadata_df.explode('columns').reset_index(drop=True)\n","col_metadata_df = col_metadata_df.dropna(subset=['columns']).reset_index(drop=True)\n","col_metadata_df = pd.concat([col_metadata_df['data_uuid'], pd.json_normalize(col_metadata_df['columns'])], axis=1)\n","# col_metadata_df.notnull().mean().sort_values(ascending=False)[:7].index.tolist()\n","col_metadata_df = col_metadata_df[['data_uuid', 'id', 'tableColumnId', 'name', 'fieldName', 'dataTypeName', 'description']]\n","col_metadata_df['description'] = col_metadata_df['description'].replace('',np.nan)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OKzBd3-KNKXM"},"source":["import gensim\n","import gensim.downloader as api\n","# glove_model = api.load('glove-wiki-gigaword-100') # glove-100dimension is 128 MB\n","\n","def remove_domain_frequent_words(input, domain_frequent_words = {}): # manually picked from 100 most common tokens\n","  output = list(set(input).difference(domain_frequent_words))\n","  return output\n","\n","def get_nan_embedding(wv_model):\n","  na_array = np.empty((wv_model.vector_size,))\n","  na_array[:] = np.nan\n","  return na_array\n","\n","def get_embedding(token, wv_model):\n","  try:\n","    return wv_model.wv[token]\n","  except:\n","    return get_nan_embedding(wv_model)\n","\n","def create_embedding(data, col, domain_frequent_words = {}):\n","  data['_tokens'] = data[col].fillna('').apply(gensim.parsing.preprocessing.remove_stopwords).apply(gensim.utils.simple_preprocess)\n","  data['_tokens_wo_domain_freq'] = data['_tokens'].apply(lambda li: remove_domain_frequent_words(li, domain_frequent_words = domain_frequent_words))\n","  data[col+'__glove_word_embedding'] = data['_tokens_wo_domain_freq'].apply(lambda li: np.nanmean([get_embedding(x, wv_model = glove_model) for x in li], axis=0) if len(li)>0 else get_nan_embedding(wv_model = glove_model) )\n","  data = data.drop(['_tokens','_tokens_wo_domain_freq'],axis=1)\n","  return data\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KAzQFKapTHyH"},"source":["col_metadata_df['name'] = col_metadata_df['name'].apply(lambda x: x.replace('_',' '))\n","col_metadata_df = create_embedding(col_metadata_df, 'name', {'nyc', 'data'})\n","col_metadata_df = create_embedding(col_metadata_df, 'description', {'nyc', 'data'})\n","col_name_based_word_embedding_for_datasets = col_metadata_df.groupby('data_uuid')['name__glove_word_embedding'].apply(list).apply(lambda li: np.nanmean(li, axis=0)).reset_index().rename(columns = {'name__glove_word_embedding':'colnames__glove_word_embedding'})\n","col_name_based_word_embedding_for_datasets['colnames__glove_word_embedding'] = col_name_based_word_embedding_for_datasets['colnames__glove_word_embedding'].apply(lambda arr: np.nan if all(np.isnan(arr)) else arr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mXS03QIBVgpd"},"source":["name_and_description_df = metadata_df[['data_uuid','name','description']].copy()\n","name_and_description_df = create_embedding(name_and_description_df, 'name', {'nyc', 'data'})\n","name_and_description_df = create_embedding(name_and_description_df, 'description', {'nyc', 'data'})\n","name_and_description_df = name_and_description_df.rename(columns = {'name__glove_word_embedding':'dataset_name__glove_word_embedding'})\n","name_and_description_df = name_and_description_df.rename(columns = {'description__glove_word_embedding':'dataset_desc__glove_word_embedding'})\n","\n","name_and_description_df['dataset_name__glove_word_embedding'] = name_and_description_df['dataset_name__glove_word_embedding'].apply(lambda arr: np.nan if all(np.isnan(arr)) else arr)\n","name_and_description_df['dataset_desc__glove_word_embedding'] = name_and_description_df['dataset_desc__glove_word_embedding'].apply(lambda arr: np.nan if all(np.isnan(arr)) else arr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bZVDKM8_YD5K"},"source":["dataset_embedding_df = pd.merge(name_and_description_df,  col_name_based_word_embedding_for_datasets, how = 'left')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_HphMzibYEKH"},"source":["dataset_embedding_df['dataset_embedding'] = dataset_embedding_df[['colnames__glove_word_embedding','dataset_name__glove_word_embedding','dataset_desc__glove_word_embedding']].apply(lambda row: row['colnames__glove_word_embedding'] if not isinstance(row['colnames__glove_word_embedding'],float) else row['dataset_name__glove_word_embedding'] if not isinstance(row['dataset_name__glove_word_embedding'], float) else row['dataset_desc__glove_word_embedding'] ,axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-jHmuHWVZQJD"},"source":["assert(dataset_embedding_df['dataset_embedding'].isnull().mean()==0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FyYKc4vmaq9z"},"source":["dataset_embedding_df[['data_uuid','dataset_embedding']].to_csv('/content/drive/MyDrive/metavis/dataset_embedding_v20211117.csv',index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bJkarq-5aFcZ"},"source":["import ast\n","import numpy as np\n","def from_np_array(array_string):\n","  # https://stackoverflow.com/a/42756309\n","  array_string = ','.join(array_string.replace('[ ', '[').split())\n","  return np.array(ast.literal_eval(array_string))\n","test = pd.read_csv('/content/drive/MyDrive/metavis/dataset_embedding_v20211117.csv', converters={'dataset_embedding': from_np_array})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"id":"1xjXLJqUazC3","executionInfo":{"status":"ok","timestamp":1637195033762,"user_tz":300,"elapsed":9,"user":{"displayName":"Tim Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0Mbx_gve9TlcvS-Od6nAnJwp6jEIt8BeHBKSp=s64","userId":"18355578200475546173"}},"outputId":"20c79b1f-4ab7-4e5e-e66c-88ddcd3a966e"},"source":["test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>data_uuid</th>\n","      <th>dataset_embedding</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2232-dj5q</td>\n","      <td>[0.272886902, 0.651672661, 0.164423525, 0.084857516, -0.0819666684, 0.453292221, 0.0757249966, 0.303720921, -0.2717686, 0.226315737, 0.287404418, -0.0704451799, 0.387170464, 0.00168698095, 0.26273...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>22gm-5ceg</td>\n","      <td>[-0.03767802, -0.07734199, -0.1406482, -0.09372941, 0.0608364, -0.04342001, -0.403372, 0.51750602, 0.39915959, 0.325266, -0.40449339, -0.25346, 0.16364799, -0.38072072, 0.03767188, -0.1352002, 0.3...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>22rr-ujq3</td>\n","      <td>[-0.09199004, -0.09967875, 0.00158188, -0.05729731, -0.36092069, 0.00770345, 0.01021996, 0.27899932, 0.39187778, 0.40246545, -0.06321181, -0.14092162, 0.2092265, 0.33034902, 0.11701665, -0.2119052...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>23z9-6uk9</td>\n","      <td>[0.11498749, 0.33656264, 0.27530958, 0.07165801, -0.20154372, -0.10274882, -0.23348022, 0.39350633, -0.05822064, 0.52232129, 0.12846081, -0.09404669, -0.08438362, 0.04706557, 0.07147856, -0.404043...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>242c-ru4i</td>\n","      <td>[-0.145268378, 0.0265072141, 0.456168638, -0.2467472, -0.0994892914, 0.46503904, -0.188583733, 0.425135664, 0.157950454, 0.287180073, -0.276847809, -0.446594164, 0.0963694876, 0.0182594338, 0.1230...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3400</th>\n","      <td>zmut-au2w</td>\n","      <td>[-0.01288117, 0.07701358, 0.34927, -0.17704557, 0.05406221, 0.1329609, -0.13549282, 0.558011, 0.12050997, 0.3571985, -0.01382237, -0.44943655, 0.39915407, -0.2620855, 0.21960932, -0.1710816, 0.422...</td>\n","    </tr>\n","    <tr>\n","      <th>3401</th>\n","      <td>zpd4-gad8</td>\n","      <td>[0.24290453, 0.2938355, 0.5160438, 0.48103797, -0.33981597, -0.4523803, 0.087005, 0.16123514, -0.3518411, 0.60383534, 0.3476553, -0.40914786, 0.2009807, -0.05200132, 0.32497835, -0.02049678, -0.16...</td>\n","    </tr>\n","    <tr>\n","      <th>3402</th>\n","      <td>zs4w-c9cd</td>\n","      <td>[0.23196084, 0.32420789, 0.49991611, 0.53018386, -0.414813, -0.52255234, 0.11655534, 0.1053189, -0.38745515, 0.6010738, 0.41343092, -0.34503776, 0.1917534, -0.04941021, 0.26384363, 0.03953277, -0....</td>\n","    </tr>\n","    <tr>\n","      <th>3403</th>\n","      <td>zt9s-n5aj</td>\n","      <td>[0.06587534, 0.397745, 0.19091167, 0.26245047, -0.19906493, 0.16047067, -0.18598931, 0.01881167, -0.20354566, 0.31177306, 0.01801765, -0.27548981, 0.134378, 0.11744719, -0.01950953, -0.16392793, 0...</td>\n","    </tr>\n","    <tr>\n","      <th>3404</th>\n","      <td>zyf6-z3xt</td>\n","      <td>[-0.43599001, 0.551395, -0.041828997, -0.37874502, 0.52877998, 0.241568, -0.690005, 0.40806496, 0.053845018, 0.0089900047, 0.59014499, 0.13130501, 0.346845, -0.47962999, 0.15721351, -0.023704976, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3405 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["      data_uuid  \\\n","0     2232-dj5q   \n","1     22gm-5ceg   \n","2     22rr-ujq3   \n","3     23z9-6uk9   \n","4     242c-ru4i   \n","...         ...   \n","3400  zmut-au2w   \n","3401  zpd4-gad8   \n","3402  zs4w-c9cd   \n","3403  zt9s-n5aj   \n","3404  zyf6-z3xt   \n","\n","                                                                                                                                                                                            dataset_embedding  \n","0     [0.272886902, 0.651672661, 0.164423525, 0.084857516, -0.0819666684, 0.453292221, 0.0757249966, 0.303720921, -0.2717686, 0.226315737, 0.287404418, -0.0704451799, 0.387170464, 0.00168698095, 0.26273...  \n","1     [-0.03767802, -0.07734199, -0.1406482, -0.09372941, 0.0608364, -0.04342001, -0.403372, 0.51750602, 0.39915959, 0.325266, -0.40449339, -0.25346, 0.16364799, -0.38072072, 0.03767188, -0.1352002, 0.3...  \n","2     [-0.09199004, -0.09967875, 0.00158188, -0.05729731, -0.36092069, 0.00770345, 0.01021996, 0.27899932, 0.39187778, 0.40246545, -0.06321181, -0.14092162, 0.2092265, 0.33034902, 0.11701665, -0.2119052...  \n","3     [0.11498749, 0.33656264, 0.27530958, 0.07165801, -0.20154372, -0.10274882, -0.23348022, 0.39350633, -0.05822064, 0.52232129, 0.12846081, -0.09404669, -0.08438362, 0.04706557, 0.07147856, -0.404043...  \n","4     [-0.145268378, 0.0265072141, 0.456168638, -0.2467472, -0.0994892914, 0.46503904, -0.188583733, 0.425135664, 0.157950454, 0.287180073, -0.276847809, -0.446594164, 0.0963694876, 0.0182594338, 0.1230...  \n","...                                                                                                                                                                                                       ...  \n","3400  [-0.01288117, 0.07701358, 0.34927, -0.17704557, 0.05406221, 0.1329609, -0.13549282, 0.558011, 0.12050997, 0.3571985, -0.01382237, -0.44943655, 0.39915407, -0.2620855, 0.21960932, -0.1710816, 0.422...  \n","3401  [0.24290453, 0.2938355, 0.5160438, 0.48103797, -0.33981597, -0.4523803, 0.087005, 0.16123514, -0.3518411, 0.60383534, 0.3476553, -0.40914786, 0.2009807, -0.05200132, 0.32497835, -0.02049678, -0.16...  \n","3402  [0.23196084, 0.32420789, 0.49991611, 0.53018386, -0.414813, -0.52255234, 0.11655534, 0.1053189, -0.38745515, 0.6010738, 0.41343092, -0.34503776, 0.1917534, -0.04941021, 0.26384363, 0.03953277, -0....  \n","3403  [0.06587534, 0.397745, 0.19091167, 0.26245047, -0.19906493, 0.16047067, -0.18598931, 0.01881167, -0.20354566, 0.31177306, 0.01801765, -0.27548981, 0.134378, 0.11744719, -0.01950953, -0.16392793, 0...  \n","3404  [-0.43599001, 0.551395, -0.041828997, -0.37874502, 0.52877998, 0.241568, -0.690005, 0.40806496, 0.053845018, 0.0089900047, 0.59014499, 0.13130501, 0.346845, -0.47962999, 0.15721351, -0.023704976, ...  \n","\n","[3405 rows x 2 columns]"]},"metadata":{},"execution_count":250}]},{"cell_type":"code","metadata":{"id":"ipen7O6tbBUz"},"source":[""],"execution_count":null,"outputs":[]}]}